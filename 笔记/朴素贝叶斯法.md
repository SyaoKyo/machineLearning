# 朴素贝叶斯法

朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布；然后基于此模型，对给定的输入<img src="http://latex.codecogs.com/gif.latex?x" />，利用贝叶斯定理求出后验概率最大的输出<img src="http://latex.codecogs.com/gif.latex?y" />。朴素贝叶斯法实现简单学习与预测的效率都很高。是一种常用的方法。

下面叙述的朴素贝叶斯法，包括朴素贝叶斯法的学习与分类、朴素贝叶斯法的参数估计算法

## 朴素贝叶斯法的学习与分类

### 基本方法

设输入空间<img src="http://latex.codecogs.com/gif.latex?\mathcal{X}\in R^n" />为<img src="http://latex.codecogs.com/gif.latex?n" />维向量的集合，输出空间为类标记集合<img src="http://latex.codecogs.com/gif.latex?\mathcal{Y}=\{c_1,c_2,\cdots,c_k\}" />。输入为特征向量<img src="http://latex.codecogs.com/gif.latex?x\in\mathcal{X}" />，输出为类标记<img src="http://latex.codecogs.com/gif.latex?y\in\mathcal{Y}" />。<img src="http://latex.codecogs.com/gif.latex?X" />是定义在输入空间<img src="http://latex.codecogs.com/gif.latex?\mathcal{X}" />上的随机向量，<img src="http://latex.codecogs.com/gif.latex?Y" />是定义在输出空间<img src="http://latex.codecogs.com/gif.latex?\mathcal{Y}" />上的随机变量。<img src="http://latex.codecogs.com/gif.latex?P(X,Y)" />是<img src="http://latex.codecogs.com/gif.latex?X" />和<img src="http://latex.codecogs.com/gif.latex?Y" />的联合概率分布。训练数据集
<div align="center"><img src="http://latex.codecogs.com/gif.latex?T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_N,y_N)\}" />
</div>

由<img src="http://latex.codecogs.com/gif.latex?P(X,Y)" />独立同分布产生。

朴素贝叶斯法通过训练数据集学习联合概率分布<img src="http://latex.codecogs.com/gif.latex?P(X,Y)" />。具体地，学习以下先验概率分布及条件概率分布。先验概率分布
<div align="center"><img src="http://latex.codecogs.com/gif.latex?P(Y=c_k),k=1,2,\cdots,K" />
</div>
条件概率分布

<div align="center"><img src="http://latex.codecogs.com/gif.latex?P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},\cdots,X^{(n)}=x^{(n)}|Y=c_k),\\k=1,2,\cdots,K" />
</div>


于是学习到联合概率分布<img src="http://latex.codecogs.com/gif.latex?P(X,Y)" />。

条件概率分布<img src="http://latex.codecogs.com/gif.latex?P(X=x|Y=c_k)" />有指数级数量的参数，其估计实际是不可行的。事实上，假设<img src="http://latex.codecogs.com/gif.latex?x^{(j)}" />可取值有<img src="http://latex.codecogs.com/gif.latex?S_j" />个，<img src="http://latex.codecogs.com/gif.latex?j=1,2,\cdots,n" />，<img src="http://latex.codecogs.com/gif.latex?Y" />可取值有<img src="http://latex.codecogs.com/gif.latex?K" />个，那么参数个数为<img src="http://latex.codecogs.com/gif.latex?K\prod^{n}_{j=1}S_j" />。

朴素贝叶斯法对条件概率分布做了条件独立性的假设。由于这是一个较强的假设，朴素贝叶斯法也由此得名。具体地，条件独立性假设是

<div align="center"><img src="http://latex.codecogs.com/gif.latex?\begin{array}{rl}P(X=x|Y=c_k)&=P(X^{(1)}=x^{(1)},\cdots,X^{(n)}=x^{(n)}|Y=c_k)\\&=\prod\limits^{n}_{j=1}P(X^{(j)}=x^{(j)}|Y=c_k)\end{array}" />
</div>

朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。这一假设使朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。

朴素贝叶斯法分类时，对给定的输入<img src="http://latex.codecogs.com/gif.latex?x" />，通过学习到的模型计算后验概率分布<img src="http://latex.codecogs.com/gif.latex?P(Y=c_k|X=x)" />，将后验概率最大的类作为<img src="http://latex.codecogs.com/gif.latex?x" />的类输出。后验概率计算根据贝叶斯定理进行：

<div align="center"><img src="http://latex.codecogs.com/gif.latex?P(Y=c_k|X=x)=\frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum\limits_kP(X=x|Y=c_k)P(Y=c_k)}" />
</div>

可得贝叶斯分类基本公式：

<div align="center"><img src="http://latex.codecogs.com/gif.latex?P(Y=c_k|X=x)=\frac{P(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)}{\sum\limits_kP(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)}" />
</div>

于是，贝叶斯分类器克表示为

<div align="center"><img src="http://latex.codecogs.com/gif.latex?y=f(x)=\arg\max_{c_k}\frac{P(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)}{\sum\limits_kP(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)}" />
</div>

注意到，在上式中分母对所有<img src="http://latex.codecogs.com/gif.latex?c_k" />都是相同的，所以，

<div align="center"><img src="http://latex.codecogs.com/gif.latex?y=f(x)=\arg\max_{c_k}P(Y=c_k)\prod\limits_jP(X^{(j)}=x^{(j)}|Y=c_k)" />
</div>

### 后验概率最大化的含义

朴素贝叶斯法将实例分到后验概率最大的类中。这等价于期望风险最小化。假设选择0-1损失函数：

<div align="center"><img src="http://latex.codecogs.com/gif.latex?L(Y,f(X))=\left\{\begin{array}{cc}1,&Y\neq f(X)\\0,&Y=f(X)\end{array}\right." />
</div>

式中<img src="http://latex.codecogs.com/gif.latex?f(X)" />是分类决策函数。这时，期望风险函数为

<div align="center"><img src="http://latex.codecogs.com/gif.latex?R_{\exp}(f)=E[L(Y,f(X))]" />
</div>

期望是对联合分布<img src="http://latex.codecogs.com/gif.latex?P(X,Y)" />取的。由此取条件期望

<div align="center"><img src="http://latex.codecogs.com/gif.latex?R_{\exp}(f)=E_X\sum\limits^K_{k=1}[L(c_k,f(X))]P(c_k|X)" />
</div>

为了使期望风险最小化，只需对<img src="http://latex.codecogs.com/gif.latex?X=x" />逐个极小化，由此得到：

<div align="center"><img src="http://latex.codecogs.com/gif.latex?\begin{array}{rl}f(x)&=\arg\min\limits_{y\in\mathcal{Y}}\sum^K_{k=1}L(c_k,y)P(c_k|X=x)\\&=\arg\min\limits_{y\in\mathcal{Y}}\sum^K_{k=1}P(y\neq c_k|X=x)\\&=\arg\min\limits_{y\in\mathcal{Y}}(1-P(y=c_k|X=x))\\&=\arg\max\limits_{y\in\mathcal{Y}}P(y=c_k|X=x)\end{array}" />
</div>

这样一来，根据期望风险最小化准则就得到了后验概率最大化准则：

<div align="center"><img src="http://latex.codecogs.com/gif.latex?f(x)=\arg\max\limits_{c_k}P(c_k|X=x)" />
</div>

即朴素贝叶斯法所采用的原理。

